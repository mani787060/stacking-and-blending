# Stacking and Blending

This project demonstrates **ensemble learning techniques** — specifically **Stacking and Blending** — to improve classification performance by combining multiple machine learning models.

## Objectives
- Understand how stacking and blending work
- Learn how multiple base models can be combined effectively
- Compare ensemble performance with individual models

## Models Used
- Random Forest Classifier
- K-Nearest Neighbors Classifier
- Gradient Boosting Classifier
- Logistic Regression (Final Estimator)

## Implementation Details
- Trained multiple base classifiers independently
- Used the predictions of base models as input features
- Applied Stacking Classifier with Logistic Regression as the final estimator
- Evaluated the final model performance using accuracy metrics
- Compared results to understand the benefit of ensemble learning

## Libraries Used
- Python
- NumPy
- Pandas
- Scikit-learn
- Matplotlib

## Learning Outcome
This project provides practical insight into advanced ensemble techniques and shows how stacking and blending can significantly improve classification performance over single models.
